{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate Schedule\n",
    "\n",
    "\n",
    "<div align='right'> Hoe Sung Ryu ( 류 회 성 ) </div>\n",
    "    \n",
    "    \n",
    "    \n",
    "<img src=https://cs231n.github.io/assets/nn3/learningrates.jpeg width=50%>    \n",
    "    \n",
    "    \n",
    "> Author: Hoe Sung Ryu, Minsuk Sung  <p>\n",
    "> Tel: 010-6636-7275 / skainf23@gamil.com // 010-5134-3621 / mssung94@gmail.com  <p>\n",
    "> 본 내용은 파이토치를 활용한 딥러닝 과외 자료입니다. 본 내용을 제작자의 동의없이 무단으로 복제하는 행위는 금합니다.\n",
    "    \n",
    "refer: https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Syllabus\n",
    "    \n",
    "|Event Type|Date|Topic|\n",
    "|--:|:---:|:---|\n",
    "|1 |July 27| Environment setting and Python basic|\n",
    "|2 |July 28| Pytorch basic and Custom Data load |\n",
    "|3 |July 29| Traditional Machine Learning(1) |\n",
    "|4 |July 30| Traditional Machine Learning(2) |\n",
    "|5 |July 31| CNN(Convolutional Neural Network)(1)  |\n",
    "|6 |Aug 03| CNN(Convolutional NeuralNetwork)(2) |\n",
    "|7 |Aug 04|  RNN(Recurrent Neural Networks)(1) |\n",
    "|8 |Aug 05|  RNN(Recurrent Neural Networks)(2) |\n",
    "|9 |Aug 06|  Transfer learning(VGG pertained on ImageNEt for CIfar-10)| \n",
    "|10|Aug 07|**Mini_Kaggle**: Facial Expression Recognition on `AffectNet` | \n",
    "|11|Aug 08|`Awards` and `Closing`| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Rate-Scheduling\" data-toc-modified-id=\"Learning-Rate-Scheduling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning Rate Scheduling</a></span></li><li><span><a href=\"#Step-wise-Decay\" data-toc-modified-id=\"Step-wise-Decay-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Step-wise Decay</a></span></li><li><span><a href=\"#Step-wise-Decay:-Every-Epoch\" data-toc-modified-id=\"Step-wise-Decay:-Every-Epoch-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Step-wise Decay: Every Epoch</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling \n",
    "\n",
    "- If we set `learning rate` to be a large value $\\rightarrow$ learn too much(rapid leanring)\n",
    "\n",
    "- If we set `learning rate` to be a small value $\\rightarrow$ learn too little(slow learning)\n",
    "\n",
    "<img src=https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/images/lr1.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step-wise Decay\n",
    "\n",
    " You would want to decay your `Learning Rate` gradually add new import as blow:\n",
    " \n",
    "```python\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "```\n",
    "\n",
    "1. At every epoch,\n",
    " - $\\eta_t = \\eta_{t-1}*\\gamma$, where $\\gamma = 1e-1$\n",
    " \n",
    " \n",
    "2. Practical example \n",
    " - Given $\\eta_t = 1e-4$ and $\\gamma = 1e-1$\n",
    " - Epoch 0: $\\eta_0= 1e-4$\n",
    " - Epoch 1: $\\eta_1= 1e-4* (1e-1) = 1e-5 $ \n",
    " - Epoch 2: $\\eta_2= 1e-4* (1e-1)^2 = 1e-7 $  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(10, 2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1.)\n",
    "steps = 10\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)\n",
    "\n",
    "for epoch in range(5):\n",
    "    #  update the learning rate for start_epoch timesb\n",
    "    for idx in range(steps):\n",
    "        scheduler.step()\n",
    "        print(scheduler.get_lr())\n",
    "    \n",
    "    print('Reset scheduler')\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:58:12.330247Z",
     "start_time": "2020-08-04T13:58:11.170170Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(42)\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:58:25.052962Z",
     "start_time": "2020-08-04T13:58:24.998550Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T13:58:32.767125Z",
     "start_time": "2020-08-04T13:58:32.762801Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:00:27.660649Z",
     "start_time": "2020-08-04T14:00:27.655946Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity\n",
    "        self.relu = nn.ReLU()\n",
    "        # Linear function (readout)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Linear function\n",
    "        out = self.fc1(x)\n",
    "        # Non-linearity\n",
    "        out = self.relu(out)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:00:36.722783Z",
     "start_time": "2020-08-04T14:00:36.718723Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "input_dim = 28*28\n",
    "hidden_dim = 100\n",
    "output_dim = 10\n",
    "\n",
    "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:00:53.770418Z",
     "start_time": "2020-08-04T14:00:53.767899Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:08:03.494832Z",
     "start_time": "2020-08-04T14:08:03.491925Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 1e-4\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-wise Decay: Every Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:08:03.867459Z",
     "start_time": "2020-08-04T14:08:03.864508Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 7: INSTANTIATE STEP LEARNING SCHEDULER CLASS\n",
    "'''\n",
    "# step_size: at how many multiples of epoch you decay\n",
    "# step_size = 1, after every 1 epoch, new_lr = lr*gamma \n",
    "# step_size = 2, after every 2 epoch, new_lr = lr*gamma \n",
    "\n",
    "# gamma = decaying factor\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:08:04.130450Z",
     "start_time": "2020-08-04T14:08:04.127844Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iteration = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:08:37.538878Z",
     "start_time": "2020-08-04T14:08:04.476108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 LR: [1.0000000000000002e-06]\n",
      "Iteration: 500. Loss: 2.290219306945801. Accuracy: 12\n",
      "Epoch: 1 LR: [1.0000000000000002e-07]\n",
      "Iteration: 1000. Loss: 2.2748613357543945. Accuracy: 12\n",
      "Epoch: 2 LR: [1.0000000000000004e-08]\n",
      "Iteration: 1500. Loss: 2.3049936294555664. Accuracy: 12\n",
      "Epoch: 3 LR: [1.0000000000000005e-09]\n",
      "Iteration: 2000. Loss: 2.2977685928344727. Accuracy: 12\n",
      "Epoch: 4 LR: [1.0000000000000006e-10]\n",
      "Iteration: 2500. Loss: 2.2933199405670166. Accuracy: 12\n",
      "Iteration: 3000. Loss: 2.3006865978240967. Accuracy: 12\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Decay Learning Rate\n",
    "    scheduler.step()\n",
    "    # Print Learning Rate\n",
    "    print('Epoch:', epoch,'LR:', scheduler.get_lr())\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images\n",
    "        images = images.view(-1, 28*28).requires_grad_()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        if iteration % 500 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to a Torch Variable\n",
    "                images = images.view(-1, 28*28)\n",
    "\n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "\n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iteration, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T16:04:29.122372Z",
     "start_time": "2020-08-04T16:04:29.110486Z"
    }
   },
   "source": [
    "<!-- ### Type of  Learning rate schedules \n",
    "- Reduce on Loss Plateau Decay \n",
    "Reduce on Loss Plateau Decay, Patience=0, Factor=0.1\n",
    "Reduce learning rate whenever loss plateaus\n",
    "- Patience: number of epochs with no improvement after which learning rate will be reduced\n",
    "a -->"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
