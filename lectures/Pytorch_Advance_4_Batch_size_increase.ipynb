{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch_Advance_4_Batch_size_increase\n",
    "<font size=5><b><b></font>\n",
    "<div align='right'> Hoe Sung Ryu ( 류 회 성 ) </div>\n",
    "\n",
    " <img src=   https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/11/Line-Plots-of-Classification-Accuracy-on-Train-and-Test-Datasets-With-Different-Batch-Sizes.png>\n",
    "    \n",
    "> Author: Hoe Sung Ryu, Minsuk Sung  <p>\n",
    "> Tel: 010-6636-7275 / skainf23@gamil.com // 010-5134-3621 / mssung94@gmail.com  <p>\n",
    "> 본 내용은 파이토치를 활용한 딥러닝 과외 자료입니다. 본 내용을 제작자의 동의없이 무단으로 복제하는 행위는 금합니다.\n",
    "    \n",
    "\n",
    "---\n",
    "\n",
    "Syllabus\n",
    "    \n",
    "|Event Type|Date|Topic|\n",
    "|--:|:---:|:---|\n",
    "|1 |July 27| Environment setting and Python basic|\n",
    "|2 |July 28| Pytorch basic and Custom Data load |\n",
    "|3 |July 29| Traditional Machine Learning(1) |\n",
    "|4 |July 30| Traditional Machine Learning(2) |\n",
    "|5 |July 31| CNN(Convolutional Neural Network)(1)  |\n",
    "|6 |Aug 03| CNN(Convolutional NeuralNetwork)(2) |\n",
    "|7 |Aug 04|  RNN(Recurrent Neural Networks)(1) |\n",
    "|8 |Aug 05|  RNN(Recurrent Neural Networks)(2) |\n",
    "|9 |Aug 06|  Transfer learning(VGG pertained on ImageNEt for CIfar-10)| \n",
    "|10|Aug 07|**Mini_Kaggle**: Facial Expression Recognition on `AffectNet` | \n",
    "|11|Aug 08|`Awards` and `Closing`| \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:40:46.796687Z",
     "start_time": "2020-08-04T14:40:44.986406Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:40:46.815007Z",
     "start_time": "2020-08-04T14:40:46.811410Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:47.724438Z",
     "start_time": "2020-08-04T14:48:47.721221Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:49.554657Z",
     "start_time": "2020-08-04T14:48:48.220622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_indices = torch.arange(0, 48000)\n",
    "valid_indices = torch.arange(48000, 50000)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((70, 70)),\n",
    "                                      transforms.RandomCrop((64, 64)),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize((70, 70)),\n",
    "                                     transforms.CenterCrop((64, 64)),\n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "train_and_valid = datasets.CIFAR10(root='data', \n",
    "                                   train=True, \n",
    "                                   transform=train_transform,\n",
    "                                   download=True)\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "test_dataset = datasets.CIFAR10(root='data', \n",
    "                                train=False, \n",
    "                                transform=test_transform,\n",
    "                                download=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=4,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=4,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:49.635860Z",
     "start_time": "2020-08-04T14:48:49.626214Z"
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:49.890089Z",
     "start_time": "2020-08-04T14:48:49.885055Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_acc(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    model.eval()\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        assert predicted_labels.size() == targets.size()\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:51.098754Z",
     "start_time": "2020-08-04T14:48:50.446970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n",
      "\n",
      "Validation Set:\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n",
      "\n",
      "Testing Set:\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "    \n",
    "# Checking the dataset\n",
    "print('\\nValidation Set:')\n",
    "for images, labels in valid_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break\n",
    "\n",
    "# Checking the dataset\n",
    "print('\\nTesting Set:')\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 2: Increasing Batch Size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:52.832599Z",
     "start_time": "2020-08-04T14:48:52.449212Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = AlexNet(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:48:52.901247Z",
     "start_time": "2020-08-04T14:48:52.898943Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_sizes = np.arange(256, 5121, 512)\n",
    "batch_size_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T14:49:20.087699Z",
     "start_time": "2020-08-04T14:48:53.514619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([768, 3, 64, 64]) torch.Size([768])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([768, 3, 64, 64]) torch.Size([768])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([768, 3, 64, 64]) torch.Size([768])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([768, 3, 64, 64]) torch.Size([768])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1280, 3, 64, 64]) torch.Size([1280])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1280, 3, 64, 64]) torch.Size([1280])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1280, 3, 64, 64]) torch.Size([1280])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1280, 3, 64, 64]) torch.Size([1280])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1792, 3, 64, 64]) torch.Size([1792])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1792, 3, 64, 64]) torch.Size([1792])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1792, 3, 64, 64]) torch.Size([1792])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n",
      "[Train]: torch.Size([1792, 3, 64, 64]) torch.Size([1792])\n",
      "[Valid]: torch.Size([256, 3, 64, 64]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cost_list = []\n",
    "train_acc_list, valid_acc_list = [], []\n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    ### INCREASE BATCH SIZE\n",
    "    if epoch > (NUM_EPOCHS//2) and not epoch % (NUM_EPOCHS//len(batch_sizes)):\n",
    "        \n",
    "#         print(int(batch_sizes[batch_size_index]))\n",
    "        train_loader = DataLoader(dataset=train_dataset, \n",
    "                                  batch_size=int(batch_sizes[batch_size_index]),\n",
    "                                  num_workers=4,\n",
    "                                  shuffle=True)\n",
    "\n",
    "        batch_size_index += 1\n",
    "       \n",
    "    images, labels = next(iter(train_loader))\n",
    "    print('[Train]:',images.shape, labels.shape)\n",
    "    images_, labels_ = next(iter(valid_loader))\n",
    "    print('[Valid]:',images_.shape, labels_.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-04T15:08:51.741498Z",
     "start_time": "2020-08-04T15:03:29.401456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 040/040 | Batch 000/027 | Cost: 2.3025 | Batchsize: 2304\n",
      "Epoch: 040/040\n",
      "Train ACC: 19.41 | Validation ACC: 20.90\n",
      "Time elapsed: 19.97 min\n",
      "Total Training Time: 19.97 min\n"
     ]
    }
   ],
   "source": [
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        #################################################\n",
    "        ### CODE ONLY FOR LOGGING BEYOND THIS POINT\n",
    "        ################################################\n",
    "        cost_list.append(cost.item())\n",
    "        if not batch_idx % 150:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f} | Batchsize: {batch_sizes[batch_size_index]}')\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        \n",
    "        train_acc = compute_acc(model, train_loader, device=DEVICE)\n",
    "        valid_acc = compute_acc(model, valid_loader, device=DEVICE)\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d}\\n'\n",
    "              f'Train ACC: {train_acc:.2f} | Validation ACC: {valid_acc:.2f}')\n",
    "        \n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
